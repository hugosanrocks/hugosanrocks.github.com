{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db77616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a918af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1000000 #MPa\n",
    "\n",
    "# For the fault figure\n",
    "cmax_f =   8000000 / scale_factor\n",
    "cmin_f =  -8000000 / scale_factor\n",
    "levels = np.linspace(cmin_f, cmax_f, 16)\n",
    "colors_l = 'w'\n",
    "\n",
    "\n",
    "xx_f, yy_f = np.loadtxt('vertx0.ts', delimiter=' ', usecols=(1, 2), unpack=True)\n",
    "tri1, tri2, tri3 = np.loadtxt('triang0.ts', dtype=int, delimiter=' ', usecols=(0, 1, 2), unpack=True)\n",
    "xx_f = xx_f/1000\n",
    "yy_f = yy_f/1000\n",
    "mu_s = 0.6\n",
    "\n",
    "tria = []\n",
    "for i in range(len(tri1)):\n",
    "    tria.append([tri1[i]-1, tri2[i]-1, tri3[i]-1])\n",
    "\n",
    "triangles = np.asarray(tria)\n",
    "# read the files\n",
    "list_files_m = glob.glob('output_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceivern*.dat')\n",
    "list_files_p = glob.glob('output_offm2p5_gapp5p0/offm2p5_gapp5p0-faultreceivern*.dat')\n",
    "list_files_m.sort()\n",
    "list_files_p.sort()\n",
    "n_files = len(list_files_m)\n",
    "n_cols = 20\n",
    "n_steps = 81\n",
    "\n",
    "k = 0\n",
    "count = 0\n",
    "data_m = np.zeros((n_files,n_steps,n_cols), dtype=np.float64)\n",
    "data_p = np.zeros((n_files,n_steps,n_cols), dtype=np.float64)\n",
    "for f in range(len(list_files_m)):\n",
    "    infile_m = open(list_files_m[f],'r')\n",
    "    infile_p = open(list_files_p[f],'r')\n",
    "    dat_m = infile_m.read()\n",
    "    vals_m = dat_m.split(\"\\n\")\n",
    "    dat_p = infile_p.read()\n",
    "    vals_p = dat_p.split(\"\\n\")\n",
    "    for i in range(n_steps):\n",
    "        val_m = vals_m[i].split(\" \")\n",
    "        val_p = vals_p[i].split(\" \")\n",
    "        for j in range(n_cols):\n",
    "            data_m[k][i][j] = float(val_m[j])\n",
    "            data_p[k][i][j] = float(val_p[j])\n",
    "    infile_m.close()\n",
    "    infile_p.close()\n",
    "    k += 1\n",
    "\n",
    "xx_m = xx_f[triangles].mean(axis = 1)\n",
    "yy_m = yy_f[triangles].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef216804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceiver-00091-00000.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceiver-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m file_name \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(rec_id_fault)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-00000.dat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m     50\u001b[0m     lines \u001b[38;5;241m=\u001b[39m fin\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     51\u001b[0m x_rec_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(lines[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m       \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100000\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceiver-00091-00000.dat'"
     ]
    }
   ],
   "source": [
    "# Load the virtual receiver coordinates (horizontal)\n",
    "xx = np.loadtxt('xx_coord.dat', usecols=(0), unpack=True)\n",
    "yy = np.loadtxt('yy_coord.dat', usecols=(0), unpack=True)\n",
    "\n",
    "xx = xx / 100000\n",
    "yy = yy / 100000\n",
    "\n",
    "vet_trace = np.loadtxt('vettore_trace_4k_depth.dat', delimiter=' ', usecols=(0,1), unpack=True)\n",
    "lag_trace = np.loadtxt('llaga_trace_overlap.dat', delimiter=' ', usecols=(0,1), unpack=True)\n",
    "lag_trace_p5 = np.loadtxt('llaga_p5_4k.dat', delimiter=' ', usecols=(0,1), unpack=True)\n",
    "lag_trace_m5 = np.loadtxt('llaga_m5_4k.dat', delimiter=' ', usecols=(0,1), unpack=True)\n",
    "\n",
    "vet_trace = vet_trace / 100000\n",
    "lag_trace = lag_trace / 100000\n",
    "lag_trace_m5 = lag_trace_m5 / 100000\n",
    "lag_trace_p5 = lag_trace_p5 / 100000\n",
    "\n",
    "# Strike vector\n",
    "stk_v = [-0.43051,   0.90259,   0.00000];\n",
    "stk_v = np.array(stk_v)\n",
    "a = [349584,  4.74132e+6,  -8500];\n",
    "b = [354640,  4.74373e+6,  -500];\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "# Dip vector\n",
    "dip_v = (a-b)/np.linalg.norm(a-b);\n",
    "\n",
    "# Normal vector to the fault\n",
    "n_v = np.cross(stk_v,dip_v);\n",
    "n_v = n_v/np.linalg.norm(n_v);\n",
    "n = n_v\n",
    "\n",
    "# Static coefficient\n",
    "mu_s = 0.6\n",
    "\n",
    "# Rotation matrix\n",
    "matrix = np.array([dip_v,stk_v,n_v])\n",
    "\n",
    "# List of files\n",
    "snaps_list = glob.glob('output_h_plus/lines_00*.dat')\n",
    "snaps_list.sort()\n",
    "\n",
    "\n",
    "# Read a given receiver and check the CFF time series at that receiver location\n",
    "rec_id_fault = 19*4 + 15\n",
    "rec_id_fault_2 = 19*6 + 7\n",
    "path = 'output_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceiver-'\n",
    "file_name = path + str(rec_id_fault).zfill(5) + '-00000.dat'\n",
    "with open(file_name) as fin:\n",
    "    lines = fin.readlines()\n",
    "x_rec_f = float(lines[2].split(\"       \")[1])/100000\n",
    "y_rec_f = float(lines[3].split(\"       \")[1])/100000\n",
    "z_rec_f = float(lines[4].split(\"      \")[1])/1000\n",
    "print(\"rec fault coords: \",x_rec_f,y_rec_f,z_rec_f)\n",
    "\n",
    "path = 'output_offm2p5_gapm5p0/offm2p5_gapm5p0-faultreceiver-'\n",
    "file_name = path + str(rec_id_fault_2).zfill(5) + '-00000.dat'\n",
    "with open(file_name) as fin:\n",
    "    lines = fin.readlines()\n",
    "x_rec_f_2 = float(lines[2].split(\"       \")[1])/100000\n",
    "y_rec_f_2 = float(lines[3].split(\"       \")[1])/100000\n",
    "z_rec_f_2 = float(lines[4].split(\"      \")[1])/1000\n",
    "print(\"rec fault coords: \",x_rec_f_2,y_rec_f_2,z_rec_f)\n",
    "\n",
    "\n",
    "\n",
    "# Horizontal dimension\n",
    "nx = 40;\n",
    "ny = 55;\n",
    "\n",
    "# Dimension vertical profile\n",
    "nstk = 31;\n",
    "nz = 30;\n",
    "\n",
    "stk = np.linspace(0,500*(nstk-1),31)\n",
    "zz = np.linspace(-500*(nz-1) + 500,500,30)\n",
    "\n",
    "stk = stk / 1000;\n",
    "zz = zz / 1000;\n",
    "\n",
    "dt_stamp = 0.1   # sampling of output files\n",
    "delay_samp = 6   # lines of header\n",
    "\n",
    "# FOR THE RECEIVER PLOT\n",
    "\n",
    "# Read a given receiver and check the CFF time series at that receiver location\n",
    "rec_id = 31*6 + 18\n",
    "path = 'output_v_plus_vet/offm2p5_gapm5p0-receiver-'\n",
    "file_name = path + str(rec_id).zfill(5) + '-00000.dat'\n",
    "with open(file_name) as fin:\n",
    "    lines = fin.readlines()\n",
    "path = 'output_v_plus_vet_f/offm2p5_gapp5p0-receiver-'\n",
    "file_name = path + str(rec_id).zfill(5) + '-00000.dat'\n",
    "with open(file_name) as fin:\n",
    "    lines_2 = fin.readlines()\n",
    "x_rec = float(lines[2].split(\"       \")[1])/100000\n",
    "y_rec = float(lines[3].split(\"       \")[1])/100000\n",
    "z_rec = float(lines[4].split(\"       \")[1])/1000\n",
    "print(\"rec coords: \",x_rec,y_rec,z_rec)\n",
    "nt = len(lines)-5\n",
    "time_rec = np.zeros((nt))\n",
    "sxx_rec = np.zeros((nt))\n",
    "syy_rec = np.zeros((nt))\n",
    "szz_rec = np.zeros((nt))\n",
    "sxy_rec = np.zeros((nt))\n",
    "syz_rec = np.zeros((nt))\n",
    "sxz_rec = np.zeros((nt))\n",
    "u_rec = np.zeros((nt))\n",
    "v_rec = np.zeros((nt))\n",
    "w_rec = np.zeros((nt))\n",
    "t1_rec = np.zeros((nt))\n",
    "t2_rec = np.zeros((nt))\n",
    "t3_rec = np.zeros((nt))\n",
    "s1_rec = np.zeros((nt))\n",
    "s2_rec = np.zeros((nt))\n",
    "s3_rec = np.zeros((nt))\n",
    "delta_tau_rec = np.zeros((nt))\n",
    "delta_sig_rec = np.zeros((nt))\n",
    "delta_cff_rec = np.zeros((nt))\n",
    "\n",
    "time_rec_2 = np.zeros((nt))\n",
    "sxx_rec_2 = np.zeros((nt))\n",
    "syy_rec_2 = np.zeros((nt))\n",
    "szz_rec_2 = np.zeros((nt))\n",
    "sxy_rec_2 = np.zeros((nt))\n",
    "syz_rec_2 = np.zeros((nt))\n",
    "sxz_rec_2 = np.zeros((nt))\n",
    "u_rec_2 = np.zeros((nt))\n",
    "v_rec_2 = np.zeros((nt))\n",
    "w_rec_2 = np.zeros((nt))\n",
    "t1_rec_2 = np.zeros((nt))\n",
    "t2_rec_2 = np.zeros((nt))\n",
    "t3_rec_2 = np.zeros((nt))\n",
    "s1_rec_2 = np.zeros((nt))\n",
    "s2_rec_2 = np.zeros((nt))\n",
    "s3_rec_2 = np.zeros((nt))\n",
    "delta_tau_rec_2 = np.zeros((nt))\n",
    "delta_sig_rec_2 = np.zeros((nt))\n",
    "delta_cff_rec_2 = np.zeros((nt))\n",
    "\n",
    "max_c = []\n",
    "min_c = []\n",
    "for i in range(nt):\n",
    "    time_rec[i] = lines[i+5].split(\"  \")[1]\n",
    "    sxx_rec[i] = lines[i+5].split(\"  \")[2]\n",
    "    syy_rec[i] = lines[i+5].split(\"  \")[3]\n",
    "    szz_rec[i] = lines[i+5].split(\"  \")[4]\n",
    "    sxy_rec[i] = lines[i+5].split(\"  \")[5]\n",
    "    syz_rec[i] = lines[i+5].split(\"  \")[6]\n",
    "    sxz_rec[i] = lines[i+5].split(\"  \")[7]\n",
    "    u_rec[i] = lines[i+5].split(\"  \")[8]\n",
    "    v_rec[i] = lines[i+5].split(\"  \")[9]\n",
    "    w_rec[i] = lines[i+5].split(\"  \")[10]\n",
    "    sig_rec = np.array([[sxx_rec[i], sxy_rec[i], sxz_rec[i]], [sxy_rec[i], syy_rec[i], syz_rec[i]], [sxz_rec[i], syz_rec[i], szz_rec[i]]])\n",
    "    t = sig_rec.dot(n)\n",
    "    # Shear and normal stress\n",
    "    tau = t - (np.dot(n,t))*n\n",
    "    sigma = np.dot(n,t)*n\n",
    "    # Rotated vectors\n",
    "    taup = matrix.dot(tau)\n",
    "    sigmap = matrix.dot(sigma)\n",
    "    t1_rec[i] = taup[0]\n",
    "    t2_rec[i] = taup[1]\n",
    "    t3_rec[i] = taup[2]\n",
    "    s1_rec[i] = sigmap[0]\n",
    "    s2_rec[i] = sigmap[1]\n",
    "    s3_rec[i] = sigmap[2]\n",
    "    delta_tau_rec[i] = t1_rec[i]            \n",
    "    #%multiply delta_sigma by -1 to change the seissol convention (negative = compression)\n",
    "    delta_sig_rec[i] = -1.0*sigmap[2]\n",
    "    delta_cff_rec[i] = delta_tau_rec[i] + mu_s*delta_sig_rec[i]\n",
    "\n",
    "    time_rec_2[i] = lines_2[i+5].split(\"  \")[1]\n",
    "    sxx_rec_2[i] = lines_2[i+5].split(\"  \")[2]\n",
    "    syy_rec_2[i] = lines_2[i+5].split(\"  \")[3]\n",
    "    szz_rec_2[i] = lines_2[i+5].split(\"  \")[4]\n",
    "    sxy_rec_2[i] = lines_2[i+5].split(\"  \")[5]\n",
    "    syz_rec_2[i] = lines_2[i+5].split(\"  \")[6]\n",
    "    sxz_rec_2[i] = lines_2[i+5].split(\"  \")[7]\n",
    "    u_rec_2[i] = lines_2[i+5].split(\"  \")[8]\n",
    "    v_rec_2[i] = lines_2[i+5].split(\"  \")[9]\n",
    "    w_rec_2[i] = lines_2[i+5].split(\"  \")[10]\n",
    "    sig_rec = np.array([[sxx_rec_2[i], sxy_rec_2[i], sxz_rec_2[i]], [sxy_rec_2[i], syy_rec_2[i], syz_rec_2[i]], [sxz_rec_2[i], syz_rec_2[i], szz_rec_2[i]]])\n",
    "    t = sig_rec.dot(n)\n",
    "    # Shear and normal stress\n",
    "    tau = t - (np.dot(n,t))*n\n",
    "    sigma = np.dot(n,t)*n\n",
    "    # Rotated vectors\n",
    "    taup = matrix.dot(tau)\n",
    "    sigmap = matrix.dot(sigma)\n",
    "    t1_rec_2[i] = taup[0]\n",
    "    t2_rec_2[i] = taup[1]\n",
    "    t3_rec_2[i] = taup[2]\n",
    "    s1_rec_2[i] = sigmap[0]\n",
    "    s2_rec_2[i] = sigmap[1]\n",
    "    s3_rec_2[i] = sigmap[2]\n",
    "    delta_tau_rec_2[i] = t1_rec_2[i]            \n",
    "    #%multiply delta_sigma by -1 to change the seissol convention (negative = compression)\n",
    "    delta_sig_rec_2[i] = -1.0*sigmap[2]\n",
    "    delta_cff_rec_2[i] = delta_tau_rec_2[i] + mu_s*delta_sig_rec_2[i]\n",
    "\n",
    "max_cff_rec = np.abs(np.max(delta_cff_rec_2)/1000000)\n",
    "min_cff_rec = np.abs(np.min(delta_cff_rec_2)/1000000)\n",
    "abs_cff_rec = np.max([max_cff_rec, min_cff_rec])\n",
    "max_cff_rec = abs_cff_rec\n",
    "min_cff_rec = -1.*abs_cff_rec\n",
    "\n",
    "counter = 0\n",
    "T_rec_m = []\n",
    "P_rec_m = []\n",
    "T_rec_p = []\n",
    "P_rec_p = []\n",
    "T_rec_m_2 = []\n",
    "P_rec_m_2 = []\n",
    "T_rec_p_2 = []\n",
    "P_rec_p_2 = []\n",
    "SRd_rec_m_2 = []\n",
    "SRd_rec_p_2 = []\n",
    "SRd_rec_m_2 = []\n",
    "SRd_rec_p_2 = []\n",
    "\n",
    "for it in snaps_list:\n",
    "    time_stamp = ( float(it.split(\"/\")[1][-8:-4]) - delay_samp ) * dt_stamp\n",
    "    time_lim =  int(it.split(\"/\")[1][-8:-4]) - delay_samp\n",
    "    print(it)\n",
    "    # Cut recording for the receiver plot\n",
    "    ttime_rec = time_rec[0:time_lim]\n",
    "    ddelta_cff_rec = delta_cff_rec[0:time_lim]\n",
    "    ttime_rec_2 = time_rec_2[0:time_lim]\n",
    "    ddelta_cff_rec_2 = delta_cff_rec_2[0:time_lim]\n",
    "    time_stamp_title = \"Time: \" + format(0.2*counter, '.1f') + ' s'\n",
    "    it_compare = 'output_h_plus_f/' + it.split(\"/\")[1]\n",
    "    out1 = 'horizontal_delta_' + str(counter).zfill(5) + '.png'\n",
    "\n",
    "    # TRIANGLES DATA\n",
    "    ##########################################\n",
    "    col_Td = 4\n",
    "    col_Pn = 5\n",
    "    fileout = 'fault_' + str(counter).zfill(5) + '.png'\n",
    "    T_d_m = []\n",
    "    P_n_m = []\n",
    "    T_d_p = []\n",
    "    P_n_p = []\n",
    "    SRd_p = []\n",
    "    SRd_m = []\n",
    "    for i in range(len(xx_f)):\n",
    "        # T_d column 4\n",
    "        # P_n column 5\n",
    "        T_d_m.append(data_m[i][counter][col_Td])\n",
    "        P_n_m.append(data_m[i][counter][col_Pn])\n",
    "        T_d_p.append(data_p[i][counter][col_Td])\n",
    "        P_n_p.append(data_p[i][counter][col_Pn])\n",
    "        SRd_p.append(data_p[i][counter][2])\n",
    "        SRd_m.append(data_m[i][counter][2])\n",
    "    # Receiver on fault #1\n",
    "    T_rec_m.append(data_m[rec_id_fault][counter][col_Td])\n",
    "    P_rec_m.append(data_m[rec_id_fault][counter][col_Pn])    \n",
    "    T_rec_p.append(data_p[rec_id_fault][counter][col_Td])\n",
    "    P_rec_p.append(data_p[rec_id_fault][counter][col_Pn])    \n",
    "    T_rec_m_arr = np.asarray(T_rec_m)\n",
    "    P_rec_m_arr = np.asarray(P_rec_m)\n",
    "    T_rec_p_arr = np.asarray(T_rec_p)\n",
    "    P_rec_p_arr = np.asarray(P_rec_p)\n",
    "    tt = np.linspace(0,(counter*0.2),counter+1)\n",
    "    D_cff_rec_m = T_rec_m_arr - mu_s * P_rec_m_arr\n",
    "    D_cff_rec_p = T_rec_p_arr - mu_s * P_rec_p_arr    \n",
    "    # Receiver on fault #2\n",
    "    T_rec_m_2.append(data_m[rec_id_fault_2][counter][col_Td])\n",
    "    P_rec_m_2.append(data_m[rec_id_fault_2][counter][col_Pn])    \n",
    "    T_rec_p_2.append(data_p[rec_id_fault_2][counter][col_Td])\n",
    "    P_rec_p_2.append(data_p[rec_id_fault_2][counter][col_Pn])    \n",
    "    T_rec_m_2_arr = np.asarray(T_rec_m_2)\n",
    "    P_rec_m_2_arr = np.asarray(P_rec_m_2)\n",
    "    T_rec_p_2_arr = np.asarray(T_rec_p_2)\n",
    "    P_rec_p_2_arr = np.asarray(P_rec_p_2)\n",
    "    D_cff_rec_m_2 = T_rec_m_2_arr - mu_s * P_rec_m_2_arr\n",
    "    D_cff_rec_p_2 = T_rec_p_2_arr - mu_s * P_rec_p_2_arr    \n",
    "    SRd_m_rec.append(data_m[rec_id_fault][counter][2])\n",
    "    SRd_p_rec.append(data_p[rec_id_fault][counter][2])\n",
    "    SRd_m_rec_2.append(data_m[rec_id_fault_2][counter][2])\n",
    "    SRd_p_rec_2.append(data_p[rec_id_fault_2][counter][2])\n",
    "\n",
    "    SRd_p_rec_2_arr = np.asarray(SRd_p_rec_2)\n",
    "    SRd_m_rec_2_arr = np.asarray(SRd_m_rec_2)\n",
    "    SRd_p_rec_arr = np.asarray(SRd_p_rec)\n",
    "    SRd_m_rec_arr = np.asarray(SRd_m_rec)\n",
    "    \n",
    "    \n",
    "    T_d_m = np.asarray(T_d_m)\n",
    "    P_n_m = np.asarray(P_n_m) * -1. # seissol convention test\n",
    "    T_d_p = np.asarray(T_d_p)\n",
    "    P_n_p = np.asarray(P_n_p) * -1.\n",
    "    D_cff_m = T_d_m - mu_s * P_n_m\n",
    "    D_cff_p = T_d_p - mu_s * P_n_p\n",
    "    D_cff_m = D_cff_m / scale_factor\n",
    "    D_cff_p = D_cff_p / scale_factor\n",
    "    \n",
    "    #max_c_m.append(max(D_cff_m))\n",
    "    #min_c_m.append(min(D_cff_m))\n",
    "    #max_c_p.append(max(D_cff_p))\n",
    "    #min_c_p.append(min(D_cff_p))\n",
    "    #zfaces_m = SRd_m[triangles].mean(axis = 1) #D_cff_m[triangles].mean(axis = 1)\n",
    "    #zfaces_p = #D_cff_p[triangles].mean(axis = 1)\n",
    "    ########################################\n",
    "\n",
    "    counter = counter + 1\n",
    "\n",
    "    #Load the data horizontal\n",
    "    time_hm, sxx_hm, syy_hm, szz_hm, sxy_hm, syz_hm, sxz_hm, u_hm, v_hm, w_hm = np.loadtxt(it_compare, delimiter=' ', usecols=(0,1,2,3,4,5,6,7,8,9), unpack=True)\n",
    "\n",
    "    #Load the data horizontal\n",
    "    time_hp, sxx_hp, syy_hp, szz_hp, sxy_hp, syz_hp, sxz_hp, u_hp, v_hp, w_hp = np.loadtxt(it, delimiter=' ', usecols=(0,1,2,3,4,5,6,7,8,9), unpack=True)\n",
    "\n",
    "    # Save space for variables\n",
    "    t1_hm = np.zeros((ny,nx))\n",
    "    t2_hm = np.zeros((ny,nx))\n",
    "    t3_hm = np.zeros((ny,nx))\n",
    "    s1_hm = np.zeros((ny,nx))\n",
    "    s2_hm = np.zeros((ny,nx))\n",
    "    s3_hm = np.zeros((ny,nx))\n",
    "    delta_tau_hm = np.zeros((ny,nx))\n",
    "    delta_sig_hm = np.zeros((ny,nx))\n",
    "    delta_cff_hm = np.zeros((ny,nx))\n",
    "    uhm = np.zeros((ny,nx))\n",
    "    vhm = np.zeros((ny,nx))\n",
    "    whm = np.zeros((ny,nx))\n",
    "\n",
    "    # Save space for variables\n",
    "    t1_hp = np.zeros((ny,nx))\n",
    "    t2_hp = np.zeros((ny,nx))\n",
    "    t3_hp = np.zeros((ny,nx))\n",
    "    s1_hp = np.zeros((ny,nx))\n",
    "    s2_hp = np.zeros((ny,nx))\n",
    "    s3_hp = np.zeros((ny,nx))\n",
    "    delta_tau_hp = np.zeros((ny,nx))\n",
    "    delta_sig_hp = np.zeros((ny,nx))\n",
    "    delta_cff_hp = np.zeros((ny,nx))\n",
    "    uhp = np.zeros((ny,nx))\n",
    "    vhp = np.zeros((ny,nx))\n",
    "    whp = np.zeros((ny,nx))\n",
    "\n",
    "    \n",
    "    #invert order\n",
    "    ndata_hm = len(time_hm);\n",
    "    k = ndata_hm-1;\n",
    "    n = n_v;\n",
    "    ii = nx;\n",
    "    for i in range(nx):\n",
    "        jj = ny;\n",
    "        for j in range(ny):\n",
    "            sig_hm = np.array([[sxx_hm[k], sxy_hm[k], sxz_hm[k]], [sxy_hm[k], syy_hm[k], syz_hm[k]], [sxz_hm[k], syz_hm[k], szz_hm[k]]])\n",
    "            t = sig_hm.dot(n)\n",
    "            # Shear and normal stress\n",
    "            tau = t - (np.dot(n,t))*n\n",
    "            sigma = np.dot(n,t)*n\n",
    "            # Rotated vectors\n",
    "            taup = matrix.dot(tau)\n",
    "            sigmap = matrix.dot(sigma)\n",
    "            t1_hm[j][i] = taup[0]\n",
    "            t2_hm[j][i] = taup[1]\n",
    "            t3_hm[j][i] = taup[2]\n",
    "            s1_hm[j][i] = sigmap[0]\n",
    "            s2_hm[j][i] = sigmap[1]\n",
    "            s3_hm[j][i] = sigmap[2]\n",
    "            delta_tau_hm[j][i] = t1_hm[j][i]            \n",
    "            #%multiply delta_sigma by -1 to change the seissol convention (negative = compression)\n",
    "            delta_sig_hm[j][i] = -1.0*sigmap[2]\n",
    "            delta_cff_hm[j][i] = delta_tau_hm[j][i] + mu_s*delta_sig_hm[j][i]\n",
    "            uhm[j][i] = u_hm[k]\n",
    "            vhm[j][i] = v_hm[k]\n",
    "            whm[j][i] = w_hm[k]\n",
    "            jj = jj-1\n",
    "            k=k-1\n",
    "    delta_cff_hm = delta_cff_hm / scale_factor\n",
    "\n",
    "    #invert order\n",
    "    ndata_hp = len(time_hp);\n",
    "    k = ndata_hp-1;\n",
    "    n = n_v;\n",
    "    ii = nx;\n",
    "    for i in range(nx):\n",
    "        jj = ny;\n",
    "        for j in range(ny):\n",
    "            sig_hp = np.array([[sxx_hp[k], sxy_hp[k], sxz_hp[k]], [sxy_hp[k], syy_hp[k], syz_hp[k]], [sxz_hp[k], syz_hp[k], szz_hp[k]]])\n",
    "            t = sig_hp.dot(n)\n",
    "            # Shear and normal stress\n",
    "            tau = t - (np.dot(n,t))*n\n",
    "            sigma = np.dot(n,t)*n\n",
    "            # Rotated vectors\n",
    "            taup = matrix.dot(tau)\n",
    "            sigmap = matrix.dot(sigma)\n",
    "            t1_hp[j][i] = taup[0]\n",
    "            t2_hp[j][i] = taup[1]\n",
    "            t3_hp[j][i] = taup[2]\n",
    "            s1_hp[j][i] = sigmap[0]\n",
    "            s2_hp[j][i] = sigmap[1]\n",
    "            s3_hp[j][i] = sigmap[2]\n",
    "            delta_tau_hp[j][i] = t1_hp[j][i]            \n",
    "            #%multiply delta_sigma by -1 to change the seissol convention (negative = compression)\n",
    "            delta_sig_hp[j][i] = -1.0*sigmap[2]\n",
    "            delta_cff_hp[j][i] = delta_tau_hp[j][i] + mu_s*delta_sig_hp[j][i]\n",
    "            uhp[j][i] = u_hp[k]\n",
    "            vhp[j][i] = v_hp[k]\n",
    "            whp[j][i] = w_hp[k]\n",
    "            jj = jj-1\n",
    "            k=k-1\n",
    "    delta_cff_hp = delta_cff_hp / scale_factor\n",
    "\n",
    "    # Figures    hf, ha = plt.subplots(3,2)\n",
    "\n",
    "    ninter = 5\n",
    "  # for contour plots\n",
    "    c_max_d =  8000000 / scale_factor\n",
    "    c_min_d = -8000000 / scale_factor\n",
    "    \n",
    "    c_min_s = -5000000\n",
    "    c_max_s =  5000000\n",
    "    \n",
    "    c_min_w = -0.37\n",
    "    c_max_w =  0.32\n",
    "    \n",
    "    \n",
    "    inter_d = np.linspace(c_min_d,c_max_d,ninter)\n",
    "    inter_s = np.linspace(c_min_s,c_max_s,ninter)\n",
    "    inter_w = np.linspace(c_min_w,c_max_w,ninter)\n",
    "\n",
    "    cmap = matplotlib.cm.get_cmap('jet')\n",
    "    \n",
    "    # DELTA PLOTS\n",
    "    fig1, axs1 = plt.subplots(2, 3, dpi=300, facecolor='white')\n",
    "    fig1.suptitle(time_stamp_title, x=0.9)\n",
    "    # delta tau\n",
    "    # Delta CFF\n",
    "    ax1 = axs1[0, 0]\n",
    "    c = ax1.pcolor(xx, yy, delta_cff_hm, cmap=cmap, vmin=c_min_d, vmax=c_max_d)\n",
    "    d = ax1.plot(vet_trace[0][:], vet_trace[1][:], linestyle='dashed', color='black', linewidth=0.3)\n",
    "    e = ax1.plot(lag_trace_p5[0][:], lag_trace_p5[1][:], linestyle='dashed', color='black', linewidth=0.3)\n",
    "    #ax1.scatter(x_rec, y_rec, 10, marker='o', color='black', facecolors='none')\n",
    "    #f = ax3.contour(xx, yy, delta_cff_h, inter_d, colors='white', linewidth=0.4)\n",
    "    ax1.set_position([0.1,0.6, 0.3, 0.34])\n",
    "    ax1.set_title(r'$\\Delta$CFF', fontsize='large')\n",
    "    ax1.axis('equal')\n",
    "    ax1.set_aspect('equal', 'box')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    \n",
    "    ax2 = axs1[0, 1]\n",
    "    c = ax2.pcolor(xx, yy, delta_cff_hp, cmap=cmap, vmin=c_min_d, vmax=c_max_d)\n",
    "    d = ax2.plot(vet_trace[0][:], vet_trace[1][:], linestyle='dashed', color='black', linewidth=0.3)\n",
    "    e = ax2.plot(lag_trace_m5[0][:], lag_trace_m5[1][:], linestyle='dashed', color='black', linewidth=0.3)\n",
    "    #ax2.scatter(x_rec, y_rec, 10, marker='o', color='black', facecolors='none')\n",
    "    #f = ax3.contour(xx, yy, delta_cff_h, inter_d, colors='white', linewidth=0.4)\n",
    "    ax2.set_position([0.28,0.6, 0.3, 0.34])\n",
    "    ax2.set_title(r'$\\Delta$CFF', fontsize='large')\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.axis('equal')\n",
    "    ax2.set_aspect('equal', 'box')\n",
    "    ax2.set_xlabel('Longitude')\n",
    "\n",
    "    #ax3.set_position([0.35,0.1, 0.35, 0.35])\n",
    "    cbaxes = fig1.add_axes([0.53, 0.595, 0.02, 0.345]) \n",
    "    cb = fig1.colorbar(c, ax=ax1, cax=cbaxes)\n",
    "    cb.set_label('Stress change (MPa)')\n",
    "\n",
    "    ax3 = axs1[1, 0]\n",
    "    hp = ax3.plot(tt, D_cff_rec_p, lw=1, color='tab:blue')\n",
    "    hm = ax3.plot(tt, D_cff_rec_m, lw=1, color='tab:blue', linestyle='dashed')\n",
    "    #just for the legend\n",
    "    hp = ax3.plot(tt, 50e6+D_cff_rec_p, lw=2, color='black', label='Vet_on_footwall')\n",
    "    hm = ax3.plot(tt, 50e6+D_cff_rec_m, lw=2, color='black', linestyle='dashed', label='Vet_on_hangingwall')\n",
    "    #end of thing for the legend\n",
    "    ax3.scatter(y_rec_f*100, z_rec_f, 20, edgecolor='black', color='blue', label='Shallow')\n",
    "    ax3.set_position([0.16,0.25, 0.47, 0.15])\n",
    "    ax3.set_xlim((0, np.max(time_rec)))\n",
    "    #ax3.set_ylim((np.min(delta_cff_rec_2)*1.3, np.max(delta_cff_rec_2)*1.3))\n",
    "    ax3.set_ylim((-500000, 500000))\n",
    "    #ax3.set_xlabel('Time (s)')\n",
    "    ax3.set_xticklabels([])\n",
    "    ax3.set_ylabel(r'$\\Delta$CFF (MPa)')\n",
    "    ax3.grid()\n",
    "    leg = ax3.legend(ncol=2, loc=[0.12, 1.01], prop={'size': 8})\n",
    "    leg.get_frame().set_edgecolor('none')\n",
    "    leg.get_frame().set_facecolor('none')\n",
    "\n",
    "    ax6 = axs1[0, 2]\n",
    "    hp = ax6.plot(tt, D_cff_rec_p_2, lw=1, color='tab:red')\n",
    "    hm = ax6.plot(tt, D_cff_rec_m_2, lw=1, color='tab:red', linestyle='dashed')\n",
    "    ax6.scatter(y_rec_f_2*100, z_rec_f_2, 20, edgecolor='black', color='red', label='Deep')\n",
    "    ax6.set_position([0.16,0.05, 0.47, 0.15])\n",
    "    ax6.set_xlim((0, np.max(time_rec)))\n",
    "    #ax3.set_ylim((np.min(delta_cff_rec_2)*1.3, np.max(delta_cff_rec_2)*1.3))\n",
    "    ax6.set_ylim((-500000, 500000))\n",
    "    ax6.set_xlabel('Time (s)')\n",
    "    ax6.set_ylabel(r'$\\Delta$CFF (MPa)')\n",
    "    ax6.grid()\n",
    "    leg = ax6.legend(ncol=2, loc=[0.7, 1.01], prop={'size': 8})\n",
    "    leg.get_frame().set_edgecolor('none')\n",
    "    leg.get_frame().set_facecolor('none')\n",
    "\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap('seismic')\n",
    "\n",
    "    c_max_d =  250000 / scale_factor\n",
    "    c_min_d = -250000 / scale_factor\n",
    "    levels = np.linspace(c_min_d, c_max_d, 6)\n",
    "\n",
    "    ax4 = axs1[1, 1]\n",
    "    ax4.set_aspect('equal')\n",
    "    ax4.set_position([0.75,0.2, 0.25, 0.25])\n",
    "    tpc_m = ax4.tripcolor(xx_f, yy_f, triangles,\n",
    "                    facecolors = zfaces_m,\n",
    "                    cmap = cmap,\n",
    "                    edgecolors ='k',\n",
    "                    #shading = 'flat',\n",
    "                    vmax = c_max_d,\n",
    "                    vmin = c_min_d)\n",
    "    #tc = ax4.tricontour(xx_m, yy_m, zfaces_m, levels=levels, linewidths=0.2, colors=colors_l)\n",
    "    tcl = ax4.clabel(tc, colors='w', fontsize=3, inline=1, fmt = '%1.0f')\n",
    "    ax4.scatter(y_rec_f*100, z_rec_f, 5, edgecolor='black', color='blue')\n",
    "    ax4.scatter(y_rec_f_2*100, z_rec_f_2, 5, edgecolor='black', color='red')\n",
    "    ax4.set_ylabel('Depth (km)')\n",
    "\n",
    "    cbaxes = fig1.add_axes([0.76, 0.11, 0.23, 0.03]) \n",
    "    cb = fig1.colorbar(tpc_m, ax=ax4, cax=cbaxes, orientation='horizontal')\n",
    "    cb.set_label('Stress change (MPa)')\n",
    "    \n",
    "    c_max_d =   250000 / scale_factor\n",
    "    c_min_d =  -250000 / scale_factor\n",
    "    levels = np.linspace(c_min_d, c_max_d, 6)\n",
    "\n",
    "    ax5 = axs1[1, 2]\n",
    "    ax5.set_aspect('equal')\n",
    "    ax5.set_position([0.75,0.68, 0.25, 0.25])\n",
    "    #ax5.set_xticklabels([])\n",
    "    tpc_p = ax5.tripcolor(xx_f, yy_f, triangles,\n",
    "                    facecolors = zfaces_p,\n",
    "                    cmap = cmap,\n",
    "                    edgecolors ='k',\n",
    "                    #shading = 'flat',\n",
    "                    vmax = c_max_d,\n",
    "                    vmin = c_min_d)\n",
    "    #tc = ax5.tricontour(xx_m, yy_m, zfaces_p, levels=levels, linewidths=0.2, colors=colors_l)\n",
    "    tcl = ax5.clabel(tc, colors='w', fontsize=5, inline=1, fmt = '%1.0f')\n",
    "    ax5.scatter(y_rec_f*100, z_rec_f, 5, edgecolor='black', color='blue')\n",
    "    ax5.scatter(y_rec_f_2*100, z_rec_f_2, 5, edgecolor='black', color='red')\n",
    "    ax5.set_ylabel('Depth (km)')\n",
    "    \n",
    "    cbaxes = fig1.add_axes([0.76, 0.59, 0.23, 0.03]) \n",
    "    cb = fig1.colorbar(tpc_p, ax=ax5, cax=cbaxes, orientation='horizontal')\n",
    "    cb.set_label('Stress change (MPa)')\n",
    "\n",
    "    \n",
    "\n",
    "    #cntr2 = ax4.tricontourf(xx_m, yy_m, zfaces, levels=14, cmap=\"RdBu_r\")\n",
    "    \n",
    "    fig1.savefig(out1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c442bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_rec_f_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my_rec_f_2\u001b[49m,z_rec_f_2,\u001b[38;5;28mlen\u001b[39m(triangles),\u001b[38;5;28mlen\u001b[39m(xx_f),\u001b[38;5;28mlen\u001b[39m(zfaces_m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_rec_f_2' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_rec_f_2,z_rec_f_2,len(triangles),len(xx_f),len(zfaces_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44535d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
